---
title: "Latent Dirichlet allocation (LDA): MIT Case Study"
author: "Randall Shane"
date: "7/15/2017"
output: html_document
---

Latent Dirichlet allocation (LDA) is an unsupervised learning topic model and one of its applications is to discover common themes, or topics that might occur across a collection of documents. The process followed here is based off a case study provided by MIT Professional Education Digital Programs, Data Science: Data to Insights, "Finding Themes In Project Descriptions." The study is presented by Professor Tamara Broderick. 

## The Code:

As the code is currently configured, if you download or clone this project, and run caseStudy1.2.py it will process the abstracts that I scraped from arXiv.org. The max value is set at 0.001 so the model will probably converge at approximately 270 iterations.

There are several text files that include the faculty data, the abstract documents (./Abrstracts), and the output from my analysis (./gamma, /.lambda). You can use this data, or download the data yourself. You will need to uncomment sections of the caseStudy1.2.py file. 

The dataPreprocessing.py file does all of the scraping, and preprocessing (prepaing the text - word stemming, etc.). The vocalbulary.py processes the data to create a vocabulary for the analysis, and the myPlots.py has several functions for building the figures in the analysis presented at [http://www.rshane.com](https://www.rshane.com/2017/07/22/latent-dirichlet-allocation-lda-mit-case-study/). Any feedback, and/or questions is appreciated.

This code is presented as is. You will be able to see that it was a work in progress with many alterations as the analysis progressed. I left blocks of code in there just in case I decided to go back and pursue that line of thinking. For example, selecting the abstracts randomly. 

Hope it is of some value.
Thanks!
