Filename: 2001-05-25_Kaelbling.txt
Author: Kaelbling, Leslie
Citation Date: 2001/05/25
Abstract URL: https://arxiv.org//abs/cs/0105032
Title: Learning to Cooperate via Policy Search
Abstract: Cooperative games are those in which both agents share the same payoff
structure. Value-based reinforcement-learning algorithms, such as variants of
Q-learning, have been applied to learning cooperative games, but they only
apply when the game state is completely observable to both agents. Policy
search methods are a reasonable alternative to value-based methods for
partially observable environments. In this paper, we provide a gradient-based
distributed policy-search method for cooperative games and compare the notion
of local optimum to that of Nash equilibrium. We demonstrate the effectiveness
of this method experimentally in a small, partially observable simulated soccer
domain.
